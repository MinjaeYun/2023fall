{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376a268b",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning + Heterogeneous Treatment Effects\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1iJfH3FN55H4XLgzu--1ECZGv-vWVWjel/view?usp=sharing)\n",
    "\n",
    "1. Causality primer/review\n",
    "2. Machine learning (ML) prediction primer/review\n",
    "3. Heterogeneous treatment effects\n",
    "    - When they matter\n",
    "    - Conceptual framework\n",
    "    - Using ML to predict treatment effects:\n",
    "4. Random Causal Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0dd0c",
   "metadata": {},
   "source": [
    "**Causal Assumption for Estimates:** Causal estimates rely on the assumption that potential outcomes are independent of treatment assignment, given covariates:\n",
    "\n",
    "1. Target (for now!):\n",
    "\n",
    "$$ ATE = E[Y_i(1) − Y_i(0)] = E [\\tau_i]$$\n",
    "\n",
    "2. Key identifying assumption:\n",
    "$$(Y_i(0), Y_i (1)) \\perp D_i|X_i$$\n",
    "\n",
    "3. Estimation:\n",
    "- Multiple linear regression (OLS)\n",
    "$$Yi = \\beta_0 + \\tau D_i + \\beta_1 \\times X_{1i} + · · · + \\beta_k \\times X_{ki} + \\epsilon$$\n",
    "- Matching\n",
    "- Propensity score methods\n",
    "- Machine-assisted:\n",
    "    - Post-Double Selection Lasso\n",
    "    - Double/De-biased Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d13e21f",
   "metadata": {},
   "source": [
    "## Predicting heterogeneous treatment effects\n",
    "\n",
    "What is the effect of job training on the probability of finding a job . . .\n",
    "- for more-educated vs. less-educated individuals?\n",
    "- for men vs. women?\n",
    "- for married vs. single?\n",
    "- for high-earning vs. low-earning (prior to training)?\n",
    "- for minorities vs. non-minorities?\n",
    "- Why does it matter?\n",
    "- Other examples where heterogeneity in treatment effects matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c16908",
   "metadata": {},
   "source": [
    "## Traditional heterogeneity analysis: Interacted regression\n",
    "\n",
    "To estimate the overall average effect:\n",
    "$$Y_i = \\tau D_i + \\epsilon_i$, $i \\in {1, . . . , n}$$\n",
    "\n",
    "To explore heterogeneity by sex:\n",
    "\n",
    "$$Y_i = \\tau^{female}D_i + \\epsilon_i$, $i : Female_i = 1$$\n",
    "\n",
    "$$Y_i = \\tau^{male}D_i + \\epsilon_i$, $i : Female_i = 0$$,\n",
    "\n",
    "or, equivalently:\n",
    "\n",
    "$$Y_i = \\tau^{male}D_i + \\beta Female_i + \\gamma D_i \\times Female_i + \\epsilon_i$$\n",
    "\n",
    "$$\\tau^{female} = \\tau^{male} + \\gamma$$.\n",
    "\n",
    "More generally,\n",
    "$$Y_i = \\tau D_i + X′_i \\beta + D_iX′_i \\gamma + \\epsilon_i$$,\n",
    "\n",
    "$$\\tau (x) = \\tau + x′\\gamma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea8b9b",
   "metadata": {},
   "source": [
    "---\n",
    "$$Y_i = \\tau D_i + X′_i \\beta + D_iX′_i \\gamma + \\epsilon_i$$,\n",
    "\n",
    "- Functional form: treatment effects may not vary linearly with $X_i$\n",
    "- Curse of dimensionality: when $X_i$ includes many variables, OLS impractical or infeasible\n",
    "- These are problems ML was born to solve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4c051",
   "metadata": {},
   "source": [
    "# Causal Effects via Regression\n",
    "\n",
    "Let's take up the example from the slides: what is the effect of going to a fancy college on later-life earnings? We'll use data on about 1,000 American men in the NLSY born 1980-1984 who finished college, and look at the effect of going to a private college ($D_i$) on earnings ($Y_i$) in 2015-2019 (when they were about 30-39 years old). We will be estimating an equation like this:\n",
    "\n",
    "$$\n",
    "Y_i = \\delta D_i + X_i'\\beta+\\varepsilon_i,\n",
    "$$\n",
    "\n",
    "where $X_i$ is a vector of controls, conditional on which we are willing to assume $D_i$ is as good as randomly assigned.\n",
    "\n",
    "What kinds of variables should we include in $X_i$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a67cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd  # for loading and managing datasets\n",
    "import statsmodels.api as sm  # for running regressions and getting standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLSY data\n",
    "nlsy = pd.read_csv(\n",
    "    \"https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/data/nlsy97.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data (drop obs with missing values)\n",
    "nlsy = nlsy.dropna()\n",
    "nlsy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f715f",
   "metadata": {},
   "source": [
    "Let's start with a simple (uncontrolled) regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple regression\n",
    "D = nlsy[\"privatecollege\"]\n",
    "y = nlsy[\"annualearnings\"]\n",
    "\n",
    "rhs = sm.add_constant(\n",
    "    D\n",
    ")  # you have to add the constant yourself with statsmodels!\n",
    "model = sm.OLS(y, rhs)\n",
    "results = model.fit(cov_type=\"HC3\")  # heteroskedasticity-robust\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2413d49",
   "metadata": {},
   "source": [
    "How to interpret the coefficient on $privatecollege$? As a causal effect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a1272",
   "metadata": {},
   "source": [
    "Now let's add controls for parent's education and cognitive ability as measured by ASVAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Regression with controls\n",
    "# Create D, y, x objects\n",
    "\n",
    "# Add constant\n",
    "\n",
    "# Obtain the model\n",
    "\n",
    "# Fit the model and create \"results\" obejct\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d28c0",
   "metadata": {},
   "source": [
    "How did the inclusion of controls change the estimate? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435ef05",
   "metadata": {},
   "source": [
    "## Bootstrapping Clustered Standard Errors\n",
    "- Handling within-group dependence\n",
    "- Resampling with replacement\n",
    "- Practical details and Stata resource [link](https://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf)\n",
    "- [R resource](https://www.r-bloggers.com/2013/01/the-cluster-bootstrap/)\n",
    "\n",
    "### Start with the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "np.random.seed(0) # for reproducibility\n",
    "clusters = np.random.choice(['A', 'B', 'C', 'D'], size=100) \n",
    "X = np.random.rand(100, 1)\n",
    "y = 2.5 * X.squeeze() + 3 + np.random.randn(100) * 2\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = np.random.choice(X.shape[0], size=4, replace=False)  # Get 4 random row indices\n",
    "X_sample = X[row_indices]\n",
    "print(len(X_sample))\n",
    "print(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052bac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When Right Hand Side is Pandas DataFrame object:\n",
    "row_indices = np.random.choice(rhs.shape[0], size=2, replace=False)  # Get 2 random row indices\n",
    "\n",
    "X_sample = rhs.loc[row_indices] \n",
    "X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c296ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Replacement Example\n",
    "import math\n",
    "import numpy as np\n",
    "for _ in range(math.factorial(3)):\n",
    "    print(np.random.choice(['A','B','C'], size=3, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48902ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Replacement Example\n",
    "import math\n",
    "import numpy as np\n",
    "for _ in range(math.factorial(3)):\n",
    "    print(np.random.choice(['A','B','C'], size=3, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b31ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to resample clusters\n",
    "unique_clusters = np.unique(clusters)\n",
    "unique_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9612911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample clusters with replacement\n",
    "sampled_clusters = np.random.choice(unique_clusters, size=len(unique_clusters), replace=True)\n",
    "sampled_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observations corresponding to the sampled clusters\n",
    "idx = np.isin(clusters, sampled_clusters)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sample\n",
    "X_sample = X[idx]\n",
    "y_sample = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1611599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and store the parameters\n",
    "model = sm.OLS(y_sample, sm.add_constant(X_sample)).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b495b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to repeat this across multiple interactions\n",
    "# Practice!\n",
    "# Generate a forloop to repeat this process 1,000 times\n",
    "# Save the parameters in the \"params\" object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938abc7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea323a",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede922dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def clustered_bootstrap(X, y, clusters, n_iterations):\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    params = []\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Sample clusters with replacement\n",
    "        sampled_clusters = np.random.choice(unique_clusters, size=len(unique_clusters), replace=True)\n",
    "        \n",
    "        # Get the observations corresponding to the sampled clusters\n",
    "        idx = np.isin(clusters, sampled_clusters)\n",
    "        X_sample = X[idx]\n",
    "        y_sample = y[idx]\n",
    "\n",
    "        # Fit the model and store the parameters\n",
    "        model = sm.OLS(y_sample, sm.add_constant(X_sample)).fit()\n",
    "        params.append(model.params)\n",
    "\n",
    "    return np.array(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca293d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "clusters = np.random.choice(['A', 'B', 'C', 'D'], size=100) \n",
    "X = np.random.rand(100, 1)\n",
    "y = 2.5 * X.squeeze() + 3 + np.random.randn(100) * 2\n",
    "\n",
    "# Bootstrap\n",
    "params = clustered_bootstrap(X, y, clusters, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a01c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standard errors\n",
    "standard_errors = params.std(axis=0)\n",
    "print(\"Clustered Bootstrapped Standard Errors:\", standard_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e400b8",
   "metadata": {},
   "source": [
    "## With real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5082016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretend we have a cluster\n",
    "nlsy['cluster'] = np.random.choice(['A', 'B', 'C', 'D', 'F'], size=len(nlsy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8294e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Generate the y and X variable from nlsy data\n",
    "\n",
    "# rhs = ?\n",
    "\n",
    "rhs = sm.add_constant(\n",
    "    pd.concat([D,X],axis=1)\n",
    ")\n",
    "\n",
    "# Run the predetermined bootstrap function\n",
    "\n",
    "# Compute standard errors and print\n",
    "\n",
    "# Remember we randomly assign the clusters here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f32693",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prediction Priemer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3212f3a",
   "metadata": {},
   "source": [
    "Let's use decision trees to predict which participants of the National JTPA Study were likely to find a job. We will use prior earnings, education, sex, race, and marital status as our prediction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/data/jtpahet.csv\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d4e4d",
   "metadata": {},
   "source": [
    "Import some utilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url1 = \"https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/python/plot_2d_separator.py\"\n",
    "r1 = requests.get(url1)\n",
    "\n",
    "r1.text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d30965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "import requests\n",
    "url1 = 'https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/python/plot_2d_separator.py'\n",
    "url2 = 'https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/python/plot_interactive_tree.py'\n",
    "url3 = 'https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/python/plot_helpers.py'\n",
    "url4 = 'https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/python/tools.py'\n",
    "r1 = requests.get(url1)\n",
    "r2 = requests.get(url2)\n",
    "r3 = requests.get(url3)\n",
    "r4 = requests.get(url4)\n",
    "\n",
    "# make sure your filename is the same as how you want to import\n",
    "with open('plot_2d_separator.py', 'w') as f1:\n",
    "    f1.write(r1.text)\n",
    "\n",
    "with open('plot_interactive_tree.py', 'w') as f2:\n",
    "    f2.write(r2.text)\n",
    "\n",
    "with open('plot_helpers.py', 'w') as f3:\n",
    "    f3.write(r3.text)\n",
    "\n",
    "with open('tools.py', 'w') as f4:\n",
    "    f4.write(r4.text)\n",
    "\n",
    "# now we can import\n",
    "import plot_helpers\n",
    "import tools\n",
    "import plot_2d_separator\n",
    "import plot_interactive_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1896b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34814e9",
   "metadata": {},
   "source": [
    "We'll first grow a tree using just two features (education and prior earnings) so we can visualize it easily. Let's visualize the feature space: triangles are individuals who found a job, circles are those who didn't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_helpers.discrete_scatter(\n",
    "    data[\"educ\"], # x axis\n",
    "    data[\"priorearn\"], # y axis\n",
    "    data[\"foundjob\"], # shape\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1100beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the trees\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(\n",
    "    data[[\"educ\", \"priorearn\"]].values, data[\"foundjob\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "plot_interactive_tree.plot_tree_partition(\n",
    "    data[[\"educ\", \"priorearn\"]].values,\n",
    "    data[\"foundjob\"],\n",
    "    tree,\n",
    "    ax=ax,\n",
    ")\n",
    "plot_tree(\n",
    "    tree,\n",
    "    feature_names=[\"education\", \"Prior earnings\"],\n",
    "    class_names=[\"No job\", \"Found job\"],\n",
    "    impurity=False,\n",
    "    filled=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f053c2a",
   "metadata": {},
   "source": [
    "Now let's do a random forest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458dc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X with \"educ\" and \"priorearn\" columns from data and y with \"foundjob\"\n",
    "X = data[[\"educ\", \"priorearn\"]]\n",
    "y = data['foundjob']\n",
    "# Initiate a random forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=2).fit(\n",
    "    X.values, y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for i, (ax, tree) in enumerate(zip(axes.ravel(), forest.estimators_)):\n",
    "    ax.set_title(\"Tree {}\".format(i))\n",
    "    plot_interactive_tree.plot_tree_partition(\n",
    "        X.values,\n",
    "        y,\n",
    "        tree,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "plot_2d_separator.plot_2d_separator(\n",
    "    forest,\n",
    "    X.values,\n",
    "    fill=True,\n",
    "    ax=axes[-1, -1],\n",
    "    alpha=0.4,\n",
    ")\n",
    "axes[-1, -1].set_title(\"Random Forest\")\n",
    "plot_helpers.discrete_scatter(\n",
    "    data[\"educ\"],\n",
    "    data[\"priorearn\"],\n",
    "    data[\"foundjob\"],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194d3cf",
   "metadata": {},
   "source": [
    "We only used two prediction features (prior earnings and education) for visualization. To get the best predictions, we should use all of our features. And to evaluate the quality of the prediction, we should hold out a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ad530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Define X and y with sensible variables from data:\n",
    "\n",
    "# Hold out a test test:\n",
    "# Remember `train_test_split` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would you check if the split function is correctly specified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)+len(X_test)==len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc3dd9",
   "metadata": {},
   "source": [
    "Try on your own: grow a forest with 500 trees using the training set, and evaluate the prediction accuracy on the test set. Hint: you can evaluate the prediction accuracy by doing `forest.score(X_test,y_test)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Initiate a random forest classifier with 500 trees\n",
    "\n",
    "# Evaluate the prediction accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00fcfa",
   "metadata": {},
   "source": [
    "\n",
    "## Key Challenge: Algorithms tailored for predicting outcomes can do poorly when predicting treatment effects\n",
    "### Factors that strongly predict outcomes may not strongly predict treatment effects\n",
    "$Y_i$: spending on a Lexus\n",
    "\n",
    "$D_i$: seeing an online ad for a Lexus\n",
    "\n",
    "$\\ln Y_i=\\beta_0+\\beta_1 age_i +\\beta_2 male_i + \\beta_3 D_i+\\beta_4 D_i \\times male_i +\\varepsilon_i$\n",
    "\n",
    "How do outcomes vary by age? (A lot if $\\beta_1$ is big)\n",
    "\n",
    "How do treatment effects vary by age? (not at all!)\n",
    "\n",
    "What do treatment effects vary by? (gender!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e8e04",
   "metadata": {},
   "source": [
    "So much for predicting _outcomes_. We want to predict causal effects. Back to the whiteboard!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ae662",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Predicting Outcome Vs. Predicting Treatment Effects**\n",
    "\n",
    "Target: $\\hat{y}(x) = E[Y_i|X_i=x]$ \n",
    "\n",
    "Criterion: $min E[(Y-\\hat{y}(x))^2|X_i = x]$\n",
    "\n",
    "Training data: $\\{Y_i, X_i\\}^n_{i=1}$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Target: $\\hat{\\tau}(x) = E[\\tau_i|X_i=x]$ \n",
    "\n",
    "Criterion: $min E[(\\tau_i-\\hat{\\tau}(x))^2|X_i = x]$\n",
    "\n",
    "Training data: $\\{\\tau_i, X_i\\}^n_{i=1}$\n",
    "\n",
    "\n",
    "**What would be the potential issue?**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(\\tau_i|X_i) &:=  E[Y_i(1)-Y_i(0)|X_i] \\\\\n",
    "&= E[Y_i|X_i, D_i=1] -E[Y_i|X_i, D_i=0]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- Final criterion (Athey and Imbens, 2016)\n",
    "$$\n",
    "min \\sum_i (\\tau_i - \\tau(X_i))^2 \\equiv max \\sum\\tau(X_i)^2\n",
    "$$\n",
    "\n",
    "- Be `honest`: use one set of observations to select the tree structure, and another to generate prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcdd20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Target: \n",
    "\n",
    "$$\n",
    "CATE := \\tau(x) =E[\\tau_i|X_i=x]\n",
    "$$\n",
    "\n",
    "- Key identifying assumption:\n",
    "$$(Y_i(0), Y_i (1)) \\perp D_i|X_i$$\n",
    "\n",
    "- Estimation: Random Causal Forest\n",
    "    - Grow decision trees on many bootstrapped samples\n",
    "    - Choose splits using the training set to $max \\sum \\tau(X_i)^2$\n",
    "    - Generate predictions in each leaf using the estimation set\n",
    "    - Average predictions over the trees in the forest\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305af7a",
   "metadata": {},
   "source": [
    "Let's simulate some data to show what happens when we try to use algorithm tailored to predicting outcomes for predicting treatment effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f26513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "n = 1000  # sample size\n",
    "p = 0.5  # probability of seeing the ad\n",
    "beta0 = 0\n",
    "beta1 = 0.2  # effect of age\n",
    "beta2 = (\n",
    "    -0.025\n",
    ")  # difference in average spending between males and females who don't see the ad ()\n",
    "beta3 = 0  # effect of treatment among females\n",
    "beta4 = 0.05  # differential effect of treatment among males compared to females\n",
    "sigeps = 0.02  # residual variance of outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f461d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake data\n",
    "age = np.random.randint(low=18, high=61, size=(n, 1))\n",
    "male = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "d = np.random.rand(n, 1) > (1 - p)\n",
    "epsilon = sigeps * np.random.randn(n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Data Generating Process\n",
    "lny = beta0 + beta1 * age + beta2 * male + beta3 * d + beta4 * d * male + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble as dataframe\n",
    "fakedata = pd.DataFrame(\n",
    "    np.concatenate((lny, d, age, male), axis=1), columns=[\"lny\", \"d\", \"age\", \"male\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65754023",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedata.feature_names = [\"age\", \"male\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007d5aa",
   "metadata": {},
   "source": [
    "- Note: subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60689b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = data.z == 1\n",
    "subset = data[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77720c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.z[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d1201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Find the untreated group\n",
    "\n",
    "# Find people older than 35 among the untreated group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterantively,\n",
    "condition = (data.z==0)&(data.age>35)\n",
    "subset = data[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice! \n",
    "# Define x0, x1, y0, y1\n",
    "# where x0 contains \"age\" and \"male\" variables untreated units\n",
    "\n",
    "# x1 contains treated units\n",
    "\n",
    "# y0 is the outcome among untreated units \"lny\"\n",
    "\n",
    "# y1 is the outcome among treated units \"lny\"\n",
    "\n",
    "# You can also combine the two lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20575135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterantively, use .loc function\n",
    "x0 = fakedata.loc[d == 0, [\"age\", \"male\"]]\n",
    "x1 = fakedata.loc[d == 1, [\"age\", \"male\"]]\n",
    "y0 = fakedata.loc[d == 0, [\"lny\"]]\n",
    "y1 = fakedata.loc[d == 1, [\"lny\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090eeca",
   "metadata": {},
   "source": [
    "Try on your own: fit two trees (call them `tree0` and `tree1`), each with `max_depth=2` to predict the outcome separately in the untreated ($D_i=0$) and treated ($D_i=1$) samples, using `x0` and `x1`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16918228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# fit trees\n",
    "# tree1 among treated\n",
    "\n",
    "# tree0 among untreated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display trees\n",
    "print(\"Treated tree:\")\n",
    "plot_tree(tree1, filled=True, feature_names=fakedata.feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Untreated tree:\")\n",
    "plot_tree(tree0, filled=True, feature_names=fakedata.feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14d09",
   "metadata": {},
   "source": [
    "Which variable(s) did the trees key in on? Why? Would these trees be useful for predicting treatment effects? Why or why not?\n",
    "\n",
    "How do we fix the problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e950247",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Random Causal Forest: Simulated Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e9d3f",
   "metadata": {},
   "source": [
    "[Resource](https://lost-stats.github.io/Machine_Learning/causal_forest.html)\n",
    "\n",
    "For those who might encounter difficulties with installing `econml` packages... Uncomment the command lines if you would want to run them\n",
    "\n",
    "## Installing `econml` Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install econml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c69f02",
   "metadata": {},
   "source": [
    "## Installing `econml` Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f749c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c5a68",
   "metadata": {},
   "source": [
    "## Installing `econml` Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anaconda prompt \n",
    "# conda install -c conda-forge econml on conda prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21d5ee",
   "metadata": {},
   "source": [
    "## Installing `econml` Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fe486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea511e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377cfc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dml import CausalForestDML as CausalForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: If you are getting `np.int` error, do the following:\n",
    "# pip install --force-reinstall numpy==1.23.5 \n",
    "# There is a fix for the new numpy version, but it's not released yet:\n",
    "# https://github.com/py-why/EconML/commit/0be16255f10853fc9fe0774cb5649e051dc55dff\n",
    "\n",
    "# Instantiate the Causal Forest\n",
    "estimator = CausalForest(n_estimators=500, discrete_treatment=True, criterion=\"het\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecafca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you guess how to call the function to fit the estimator?\n",
    "y = fakedata[\"lny\"]\n",
    "d = fakedata[\"d\"]\n",
    "X = fakedata[[\"age\", \"male\"]]\n",
    "\n",
    "# Grow the forest\n",
    "estimator.fit(\n",
    "    y,d,X=X  # outcome  # treatment\n",
    ")  # prediction features\n",
    "\n",
    "# Predict effects for each observation based on its characteristics:\n",
    "effects = estimator.effect(fakedata[[\"age\", \"male\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50466fe",
   "metadata": {},
   "source": [
    "Let's see how well it did at estimating effects among men and women:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df57f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Subset \"effects\" object where the observation is male in fakedata\n",
    "# Generate 'malefx' object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "malefx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Subset \"effects\" object where the observation is female in fakedata\n",
    "# Generate \"femalefx\" object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "femalefx.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3847c5",
   "metadata": {},
   "source": [
    "How did our causal forest do at getting effects right for men and women? Let's see how it does on the age profile:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca769d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Generate \"maleage\" and \"femaleage\" objects\n",
    "# that contain the age array from male observations\n",
    "\n",
    "# and contain the age array from female observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively we can use iloc function\n",
    "maleage = fakedata[\"age\"].iloc[fakedata[\"male\"].values == 1]\n",
    "femaleage = fakedata[\"age\"].iloc[fakedata[\"male\"].values == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a92dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.scatter(maleage, malefx, label=\"males\")\n",
    "ax.scatter(femaleage, femalefx, label=\"females\")\n",
    "ax.legend()\n",
    "\n",
    "# add title, x label, and y label to the plt object\n",
    "plt.title(\"Estimated Treatment effects\")\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"treatment effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0621528d",
   "metadata": {},
   "source": [
    "A little noisy on the age profile (which should be flat) but does get the difference between men and women!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21571e",
   "metadata": {},
   "source": [
    "## Random Causal Forest: Predict the effects of job training\n",
    "We are ready to apply machine learning to predict causal effects in a real-life setting: how do the effects of job training vary by an individual's characteristics? We will use data from the National Job Training Partnership study, a large-scale randomized evaluation of a publicly subsidized job training program for disadvantaged youth and young adults. Why would we care how the effects of a subsidized job training program vary by a person's characteristics?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229bb6d",
   "metadata": {},
   "source": [
    "We will use the JTPA evaluation dataset, which contains observations on about 14,000 individuals, some of whom were randomized to participate in job training ($z_i = 1$) and others who were not ($z_i = 0$).\n",
    "\n",
    "To do on your own:\n",
    "\n",
    "- load the dataset from the url `https://github.com/Mixtape-Sessions/Heterogeneous-Effects/raw/main/Labs/data/jtpahet.csv`\n",
    "- define the outcome vector (call it `y`) to be the column labeled `foundjob`\n",
    "- define the randomized assignment indicator (call it `z`) to be the column labeled `z`\n",
    "- define the feature vector (call it `x`) to be all columns except `foundjob`, `z`, and `enroll`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4624b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# load data and set things up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2e7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f432d2",
   "metadata": {},
   "source": [
    "On your own: run a linear regression of the outcome on the random assignment indicator, `z`. Since this was a randomized experiment, we don't need controls!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2da7f3",
   "metadata": {},
   "source": [
    "### Set up random forest\n",
    "So far, so good? Now create a random causal forest object, and fit it with outcome `y`, treatment variable `z`, and feature matrix `x`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice! \n",
    "# Create and fit random causal forest object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7134e1",
   "metadata": {},
   "source": [
    "### Explore effects\n",
    "Let's see what kind of heterogeneous effects our random causal forest predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e26649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the predicted effects:\n",
    "insamplefx = rcf.effect(x)\n",
    "print(rcf.ate_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d89e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap practice!\n",
    "# Use .format function to keep the four digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27770f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, flexibly keeping significant digits\n",
    "\"ATE: {:.3g}\".format(rcf.ate_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the estimated effects, with average effect overlaid\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.hist(insamplefx, bins=30, density=True)\n",
    "plt.axvline(rcf.ate_, color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.suptitle(\"Estimated Treatment effects\")\n",
    "plt.title(\"ATE: {:.3g}\".format(rcf.ate_[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934645f",
   "metadata": {},
   "source": [
    "Let's visualize how these effects vary by prior earnings and education by making a heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid of values for education and prior earnings:\n",
    "educgrid = np.arange(data[\"educ\"].values.min(), data[\"educ\"].values.max() + 1)\n",
    "earngrid = np.arange(\n",
    "    data[\"priorearn\"].values.min(), data[\"priorearn\"].values.max(), 5000\n",
    ")\n",
    "grid = pd.DataFrame(\n",
    "    itertools.product(educgrid, earngrid), columns=[\"educ\", \"priorearn\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf93f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132cd41",
   "metadata": {},
   "source": [
    "We'll first visualize the effects among married, nonwhite females of average age:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4279832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns\n",
    "grid[\"age\"] = data[\"age\"].mean()  # set age to the average\n",
    "grid[\"female\"] = 1  # set female = 1\n",
    "grid[\"nonwhite\"] = 1  # set nonwhite = 1\n",
    "grid[\"married\"] = 1  # set married = 1\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a099115",
   "metadata": {},
   "source": [
    "To do on your own: calculate the predicted effects for each \"observation\" in the grid:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2aa24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# gridfx = # uncomment and fill in on your own!\n",
    "gridfx = rcf.effect(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a949f7",
   "metadata": {},
   "source": [
    "### Visualize effects with a heatmap:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot()\n",
    "main = ax.scatter(\n",
    "    grid[\"educ\"], grid[\"priorearn\"], c=gridfx, cmap=\"plasma\", marker=\"s\", s=300\n",
    ")\n",
    "plt.suptitle(\"Estimated Treatment effects\")\n",
    "plt.title(\"Nonwhite married females\")\n",
    "plt.xlabel(\"years of education\")\n",
    "plt.ylabel(\"prior earnings\")\n",
    "\n",
    "# create an Axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(main, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb316363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8769551d",
   "metadata": {},
   "source": [
    "### Comparison to Residualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "y = data[\"foundjob\"]\n",
    "d = data[\"z\"]\n",
    "X = data.drop([\"foundjob\", \"z\", \"enroll\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854936ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Manual one-fold cross validation\n",
    "\n",
    "# 1. Subset data\n",
    "# females and earnings below 10,000\n",
    "condition = (X.female==1)&(X.priorearn<10000)\n",
    "\n",
    "X_female = X[condition]\n",
    "len(X_female)\n",
    "\n",
    "# 2. Generate a trainig and test set\n",
    "X_train_female, X_test_female, y_train_female, y_test_female = train_test_split(X_female, y[condition], test_size=0.5, random_state=0)\n",
    "\n",
    "# 3. How would you split the sets for D?\n",
    "d_train, d_test = d[X_train_female.index], d[X_test_female.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5038ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_female[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_female[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ffae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Create a Random Forest Classifier with max_depth=3\n",
    "\n",
    "# Train the classifier on the training data\n",
    "\n",
    "# Calculate residuals for y \n",
    "\n",
    "# Calculate residuals for d on entire data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1905226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear projection of y tilde on d tilde\n",
    "d_reshaped = d_residual.values.reshape(-1,1) # 1 dimensional array needs reshaping for regression packages\n",
    "y_reshaped = y_residual.values.reshape(-1,1)\n",
    "lm=LinearRegression()\n",
    "lm.fit(d_reshaped,y_reshaped)\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b62ab",
   "metadata": {},
   "source": [
    "## Stratified sample splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice!\n",
    "# Split training/test set by \"nonwhite\" status\n",
    "# Concatenate the subsets into final training/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ffb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
